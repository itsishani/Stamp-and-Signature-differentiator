{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (557214332.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    return cv2.imread(C:\\Program Files\\project_at_once\\aiqod\\in-russ.jpg)\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "from skimage.measure import regionprops\n",
    "\n",
    "def detect_text_regions(image):\n",
    "    \"\"\"Detect text regions using morphology\"\"\"\n",
    "    # Apply adaptive thresholding for better text detection\n",
    "    thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Use morphological operations to enhance text regions\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    \n",
    "    # Find contours of potential text regions\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create a mask for text regions\n",
    "    text_mask = np.zeros_like(image)\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / float(h)\n",
    "        area = w * h\n",
    "        density = cv2.countNonZero(thresh[y:y+h, x:x+w]) / area\n",
    "        \n",
    "        # Characteristics of typical text regions\n",
    "        if (0.1 < aspect_ratio < 15 and \n",
    "            10 < w < 300 and \n",
    "            5 < h < 100 and \n",
    "            0.1 < density < 0.9):\n",
    "            # Mark as text region\n",
    "            cv2.rectangle(text_mask, (x, y), (x+w, y+h), 255, -1)\n",
    "    \n",
    "    return text_mask\n",
    "\n",
    "def detect_signatures(image, text_mask):\n",
    "    \"\"\"Detect signatures by excluding text regions\"\"\"\n",
    "    # Remove text regions from the image\n",
    "    image_no_text = image.copy()\n",
    "    image_no_text[text_mask > 0] = 255\n",
    "    \n",
    "    # Threshold the image to isolate dark regions (potential signatures)\n",
    "    _, binary = cv2.threshold(image_no_text, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Apply morphological operations to enhance signature-like regions\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    binary = cv2.dilate(binary, kernel, iterations=1)\n",
    "    binary = cv2.erode(binary, kernel, iterations=1)\n",
    "    \n",
    "    # Connected component analysis\n",
    "    blobs_labels = measure.label(binary, connectivity=2)\n",
    "    regions = regionprops(blobs_labels)\n",
    "    \n",
    "    # Filter regions based on signature characteristics\n",
    "    signature_mask = np.zeros_like(image)\n",
    "    \n",
    "    for region in regions:\n",
    "        if region.area < 100:  # Skip very small regions\n",
    "            continue\n",
    "            \n",
    "        y0, x0, y1, x1 = region.bbox\n",
    "        w, h = x1 - x0, y1 - y0\n",
    "        \n",
    "        aspect_ratio = w / float(h)\n",
    "        density = region.area / (w * h)\n",
    "        perimeter_area_ratio = region.perimeter / region.area if region.area > 0 else 0\n",
    "        \n",
    "        # Signature characteristics: irregular shape, sparse density\n",
    "        if (0.5 < aspect_ratio < 10 and \n",
    "            0.05 < density < 0.2 and \n",
    "            min(w, h) > 20 and \n",
    "            max(w, h) > 50 and\n",
    "            region.solidity < 0.6 and  # Less solid, more irregular\n",
    "            perimeter_area_ratio > 0.4):  # More complex boundary\n",
    "            # Set only the exact region pixels\n",
    "            signature_mask[blobs_labels == region.label] = 255\n",
    "    \n",
    "    return signature_mask\n",
    "\n",
    "def detect_stamps(image):\n",
    "    \"\"\"Detect stamps using connected component analysis\"\"\"\n",
    "    # Blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(image.copy(), (5, 5), 0)\n",
    "    \n",
    "    # Adaptive thresholding to highlight dark stamp regions\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Connected component analysis\n",
    "    blobs_labels = measure.label(thresh, connectivity=2)\n",
    "    regions = regionprops(blobs_labels)\n",
    "    \n",
    "    stamp_mask = np.zeros_like(image)\n",
    "    \n",
    "    for region in regions:\n",
    "        if region.area < 1000 or region.area > 50000:  # Size range for stamps\n",
    "            continue\n",
    "        y0, x0, y1, x1 = region.bbox\n",
    "        w, h = x1 - x0, y1 - y0\n",
    "        aspect_ratio = w / float(h)\n",
    "        density = region.area / (w * h)\n",
    "        \n",
    "        # Stamp characteristics: near-square, solid, dense\n",
    "        if (0.7 < aspect_ratio < 1.5 and \n",
    "            region.solidity > 0.8 and  # More solid shape\n",
    "            density > 0.5):  # Higher density due to filled areas\n",
    "            # Set only the exact region pixels\n",
    "            stamp_mask[blobs_labels == region.label] = 255\n",
    "    \n",
    "    return stamp_mask\n",
    "\n",
    "def main():\n",
    "    image_path = '/content/sample1.jpg'  # Replace with your input image path\n",
    "    \n",
    "    # Read the input image in grayscale\n",
    "    img_gray = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img_gray is None:\n",
    "        print(f\"Error: Could not load image at {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # Detect text regions\n",
    "    text_mask = detect_text_regions(img_gray)\n",
    "\n",
    "    # Detect signatures (excluding text regions)\n",
    "    signature_mask = detect_signatures(img_gray.copy(), text_mask)\n",
    "\n",
    "    # Detect stamps\n",
    "    stamp_mask = detect_stamps(img_gray.copy())\n",
    "\n",
    "    # Read original image for highlighting purposes\n",
    "    original_image = cv2.imread(image_path)\n",
    "\n",
    "    # Create a version with text removed (white background)\n",
    "    text_removed_image = original_image.copy()\n",
    "    \n",
    "    # Remove normal text by setting those pixels to white\n",
    "    text_removed_image[text_mask > 0] = [255, 255, 255]\n",
    "\n",
    "    # Highlight signatures in green (BGR: [0, 255, 0])\n",
    "    highlighted_image = text_removed_image.copy()\n",
    "    \n",
    "    highlighted_image[signature_mask > 0] = [0, 255, 0]\n",
    "\n",
    "    # Highlight stamps in red (BGR: [0, 0, 255])\n",
    "    highlighted_image[stamp_mask > 0] = [0, 0, 255]\n",
    "\n",
    "    # Save or display the highlighted output image\n",
    "    output_path_highlighted = 'highlighted_output.jpg'\n",
    "    cv2_imshow(highlighted_image)\n",
    "    # If running locally, replace cv2_imshow with cv2.imshow\n",
    "    # cv2.imshow('Highlighted Image', highlighted_image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
